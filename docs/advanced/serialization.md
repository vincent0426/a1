# Serialization & Persistence

A1 supports serialization and deserialization of Agents, Tools, Runtime, and Context using Pydantic models and file persistence, enabling:

- **Durability**: Save and restore sessions
- **Distribution**: Share agents across systems
- **Versioning**: Track agent evolution
- **Collaboration**: Export/import agent configurations

## Overview

All core A1 objects support serialization:
- **JSON serialization**: Using Pydantic's `model_dump()` and `model_validate()`
- **File persistence**: `from_file()` with optional `keep_updated=True` for auto-sync
- **Manual save/load**: Full control over when state is persisted

## Context Serialization

### File Persistence with Auto-Update

```python
from a1 import Context

# Create with auto-update
ctx = Context.from_file("conversation.json", keep_updated=True)

# Any change auto-saves
ctx.user("New message")  # Automatically written to conversation.json
ctx.assistant("Response")  # Auto-saved

# Later session - reload
ctx = Context.from_file("conversation.json")
print(f"Loaded {len(ctx.messages)} messages")
```

### Basic Serialization

```python
from a1 import Context, get_context
from a1.models import Message
import json

# Create context
ctx = get_context("main")
ctx.user("Hello")
ctx.assistant("Hi there")

# Serialize to JSON
messages_data = [msg.model_dump() for msg in ctx.messages]
json_str = json.dumps(messages_data, indent=2)

# Deserialize
messages = [Message(**data) for data in json.loads(json_str)]
restored_ctx = Context(messages=messages)
```

### Manual File Persistence

```python
from a1 import Context, get_context
from a1.models import Message
import json

# Save to file manually
ctx = get_context("main")
ctx.user("Hello")

with open("context.json", "w") as f:
    json.dump([msg.model_dump() for msg in ctx.messages], f, indent=2)

# Load from file manually
with open("context.json") as f:
    messages = [Message(**data) for data in json.load(f)]
    ctx = Context(messages=messages)
```

## Agent Serialization

### Schema

```python
from a1 import Agent
from pydantic import BaseModel, Field

class Input(BaseModel):
    problem: str

class Output(BaseModel):
    answer: str

agent = Agent(
    name="solver",
    description="Solves problems",
    input_schema=Input,
    output_schema=Output,
    tools=[calculator, llm]
)

# Serialize
agent_dict = {
    "name": agent.name,
    "description": agent.description,
    "input_schema": Input.model_json_schema(),
    "output_schema": Output.model_json_schema(),
    "tools": [serialize_tool(t) for t in agent.tools]
}

# Deserialize
agent = Agent(
    name=agent_dict["name"],
    description=agent_dict["description"],
    input_schema=create_model_from_schema(agent_dict["input_schema"]),
    output_schema=create_model_from_schema(agent_dict["output_schema"]),
    tools=[deserialize_tool(t) for t in agent_dict["tools"]]
)
```

### File Persistence

```python
import json
from a1 import Agent

# Save agent definition
def save_agent(agent: Agent, path: str):
    data = {
        "name": agent.name,
        "description": agent.description,
        "input_schema": agent.input_schema.model_json_schema(),
        "output_schema": agent.output_schema.model_json_schema(),
        "tool_names": [t.name for t in agent.tools]  # Reference tools by name
    }
    with open(path, "w") as f:
        json.dump(data, f, indent=2)

# Load agent definition  
def load_agent(path: str, tool_registry: dict) -> Agent:
    with open(path) as f:
        data = json.load(f)
    
    # Reconstruct schemas
    from pydantic import create_model
    input_schema = create_model_from_schema(data["input_schema"])
    output_schema = create_model_from_schema(data["output_schema"])
    
    # Resolve tools from registry
    tools = [tool_registry[name] for name in data["tool_names"]]
    
    return Agent(
        name=data["name"],
        description=data["description"],
        input_schema=input_schema,
        output_schema=output_schema,
        tools=tools
    )
```

## Tool Serialization

### Basic Tools

```python
from a1 import Tool, tool

@tool(name="calculator", description="Do math")
async def calculator(a: float, b: float, op: str) -> float:
    ...

# Serialize
tool_dict = {
    "type": "custom",
    "name": calculator_tool.name,
    "description": calculator_tool.description,
    "input_schema": calculator_tool.input_schema.model_json_schema(),
    "output_schema": calculator_tool.output_schema.model_json_schema(),
    "module": "myapp.tools",
    "function": "calculator"
}

# Deserialize (requires importing the actual function)
import importlib
module = importlib.import_module(tool_dict["module"])
func = getattr(module, tool_dict["function"])

from a1 import tool
calculator_tool = tool(
    name=tool_dict["name"],
    description=tool_dict["description"]
)(func)
```

### LLM Tools

```python
from a1 import LLM, RetryStrategy

llm = LLM(
    model="groq:openai/gpt-oss-20b",
    retry_strategy=RetryStrategy(max_iterations=3, num_candidates=3)
)

# Serialize
llm_dict = {
    "type": "llm",
    "model": "groq:openai/gpt-oss-20b",
    "retry_strategy": {
        "max_iterations": 3,
        "num_candidates": 3
    },
    "input_schema": None,  # or schema if specified
    "output_schema": None  # or schema if specified
}

# Deserialize
llm = LLM(
    model=llm_dict["model"],
    retry_strategy=RetryStrategy(**llm_dict["retry_strategy"])
)
```

### ToolSet Serialization

```python
from a1 import ToolSet

toolset = ToolSet(
    name="math_tools",
    tools=[calculator, solver, llm]
)

# Serialize
toolset_dict = {
    "name": toolset.name,
    "tools": [serialize_tool(t) for t in toolset.tools]
}

# Deserialize
toolset = ToolSet(
    name=toolset_dict["name"],
    tools=[deserialize_tool(t) for t in toolset_dict["tools"]]
)
```

## Runtime Serialization

### File Persistence with Auto-Update

```python
from a1 import Runtime, get_context

# Create persistent runtime with auto-save
runtime = Runtime.from_file("session.json", keep_updated=True)

# All context changes auto-save
with runtime:
    ctx = get_context("main")
    ctx.user("Hello")  # Triggers save to session.json
    ctx.assistant("Hi")  # Auto-saved

# Later session - restore everything
runtime = Runtime.from_file("session.json")
with runtime:
    ctx = get_context("main")  # Restored with all history
    print(f"Loaded {len(ctx.messages)} messages")
```

The `keep_updated=True` option enables automatic persistence - every context change is immediately saved.

### Manual State Persistence

```python
from a1 import Runtime, Context, get_context
from a1.models import Message
import json

runtime = Runtime(cache_dir=".a1")

# ... use runtime ...

# Manually save runtime state
runtime_dict = {
    "cache_dir": str(runtime.cache_dir),
    "contexts": {
        name: [msg.model_dump() for msg in ctx.messages]
        for name, ctx in runtime.CTX.items()
    }
}

with open("runtime.json", "w") as f:
    json.dump(runtime_dict, f, indent=2)

# Manually restore runtime state
with open("runtime.json") as f:
    data = json.load(f)

runtime = Runtime(cache_dir=data["cache_dir"])
for name, messages in data["contexts"].items():
    runtime.CTX[name] = Context(
        messages=[Message(**msg) for msg in messages]
    )
```

## Pydantic Schema Serialization

Pydantic schemas need special handling for rehydration:

```python
from pydantic import BaseModel, Field, create_model
import json

# Original schema
class Output(BaseModel):
    answer: float = Field(..., description="The answer")
    explanation: str = Field(..., description="Explanation")

# Serialize to JSON schema
schema_json = Output.model_json_schema()
schema_str = json.dumps(schema_json)

# Deserialize - reconstruct model
def create_model_from_schema(schema: dict) -> type[BaseModel]:
    """Recreate Pydantic model from JSON schema."""
    fields = {}
    for field_name, field_info in schema.get("properties", {}).items():
        field_type = parse_type(field_info["type"])
        description = field_info.get("description", "")
        required = field_name in schema.get("required", [])
        
        if required:
            fields[field_name] = (field_type, Field(..., description=description))
        else:
            fields[field_name] = (field_type, Field(None, description=description))
    
    return create_model(schema["title"], **fields)

# Reconstruct
schema = json.loads(schema_str)
Output = create_model_from_schema(schema)
```

## Complete Example: Session Persistence

Here's how to manually manage persistent agent sessions:

```python
from a1 import Runtime, Agent, LLM, get_context
from a1.models import Message
import json
from pathlib import Path

class SessionManager:
    """Manage persistent agent sessions."""
    
    def __init__(self, session_dir: str = "sessions"):
        self.session_dir = Path(session_dir)
        self.session_dir.mkdir(exist_ok=True)
    
    def save_session(self, session_id: str, runtime: Runtime):
        """Save complete runtime state."""
        session_file = self.session_dir / f"{session_id}.json"
        
        data = {
            "contexts": {
                name: [msg.model_dump() for msg in ctx.messages]
                for name, ctx in runtime.CTX.items()
            },
            "cache_dir": str(runtime.cache_dir)
        }
        
        with open(session_file, "w") as f:
            json.dump(data, f, indent=2)
        
        print(f"✓ Session saved to {session_file}")
    
    def load_session(self, session_id: str) -> Runtime:
        """Load runtime state from session."""
        session_file = self.session_dir / f"{session_id}.json"
        
        with open(session_file) as f:
            data = json.load(f)
        
        # Create runtime
        from a1 import Context
        runtime = Runtime(cache_dir=data["cache_dir"])
        
        # Restore contexts
        for name, messages in data["contexts"].items():
            runtime.CTX[name] = Context(
                messages=[Message(**msg) for msg in messages]
            )
        
        print(f"✓ Session loaded from {session_file}")
        return runtime

# Usage
manager = SessionManager()

# Start session
runtime = Runtime()
with runtime:
    agent = Agent(...)
    result = await runtime.jit(agent, problem="...")
    
    # Save session
    manager.save_session("my-session", runtime)

# Later - resume session
runtime = manager.load_session("my-session")
with runtime:
    ctx = get_context("main")
    print(f"Restored {len(ctx.messages)} messages")
    
    # Continue where we left off
    result = await runtime.jit(agent, problem="...")
```
    
    # Save session
    manager.save_session("my-session", runtime)

# Later - resume session
runtime = manager.load_session("my-session")
with runtime:
    ctx = get_context("main")
    print(f"Restored {len(ctx)} messages")
    
    # Continue where we left off
    result = await agent.jit(problem="...")
```


## Best Practices

### 1. Use JSON for Portability
```python
# ✅ JSON is portable
with open("agent.json", "w") as f:
    json.dump(agent_dict, f)

# ❌ Pickle is fragile
import pickle
with open("agent.pkl", "wb") as f:
    pickle.dump(agent, f)
```

### 2. Version Your Schemas
```python
agent_dict = {
    "version": "1.0",
    "name": "solver",
    # ... rest of config
}

# Check version on load
if agent_dict["version"] != "1.0":
    raise ValueError("Incompatible agent version")
```

### 3. Store Tool References, Not Implementations
```python
# ✅ Store tool names
{"tools": ["calculator", "search", "llm_groq"]}

# ❌ Don't try to serialize functions
{"tools": [<function calculator>, ...]}  # Won't work!
```

### 4. Keep Sessions Organized
```python
sessions/
  user_123/
    session_001.json
    session_002.json
  user_456/
    session_001.json
```

## See Also

- [Context & History](../guide/context.md) - Context management
- [Agents](../guide/agents.md) - Agent configuration
- [Runtime](../api/runtime.md) - Runtime API reference
